# ğŸ•µï¸ DeepFake Detection Using InceptionResNetV2

This project implements a DeepFake detection system using the **InceptionResNetV2** architecture and transfer learning. The final model achieves an impressive **99.09%** accuracy on the test dataset.

---

## ğŸ“ Dataset Structure

The dataset is organized as follows:

```
real-vs-fake/
â”œâ”€â”€ train   â†’ 100,000 images (real & fake)
â”œâ”€â”€ valida  â†’ 20,000 validation images
â””â”€â”€ test    â†’ 20,000 test images
```

âœ… All images are resized to **224x224** pixels and normalized prior to training.

---

## ğŸ§  Model Architecture

**Final Architecture**:

1. **Base**: Pre-trained **InceptionResNetV2** (ImageNet weights)
2. **Top Layers**:

   * Dense layer (512 units) with **L2 regularization**
   * **BatchNormalization**
   * **Dropout** (rate = 0.5)
   * **Output layer** with **sigmoid** activation for binary classification

---

## ğŸ‹ï¸ Training Approaches

### âš™ï¸ Approach 1: Base Model Frozen

* Entire base frozen
* Used **LeakyReLU**
* **Exponential decay** learning rate (start: 1e-5)
* ğŸ•’ Avg time/epoch: 109s
* ğŸ“Š Accuracy: \~79%

---

### ğŸ”§ Approach 2: First Fine-Tuning

* First **450 layers frozen**
* Used **Adam** (LR: 1e-6)
* ğŸ•’ Avg time/epoch: 112s
* ğŸ“‰ Accuracy: \~74.4%

---

### ğŸš€ Approach 3: Advanced Fine-Tuning

* Same 450-layer freezing
* Switched to **ReLU**
* Increased LR to **0.0001**
* Enabled **early stopping** on val loss
* ğŸ•’ Avg time/epoch: 164s
* âœ… Val Accuracy: **99.73%**
* â— Val Loss: **0.4831**

---

## âœ… Final Results

* ğŸ¯ **Test Accuracy**: 99.09%
* ğŸ“‰ **Test Loss**: 0.0292
* ğŸ“€ Model saved as: `final_inceptionresnetv2_deepfake_model_99.keras`

---

## ğŸ’» Hardware Used

All experiments ran on an **NVIDIA A100 Tensor Core GPU** for high-speed training.

---

## ğŸ§ª Sample Results

| Fake Detected  | Authentic      |
| -------------- | -------------- |
| ![Fake](2.png) | ![Real](1.png) |

---

# ğŸ” Post-Training Inference

Demonstrated in \[`Models/Post-Training Inference.ipynb`]\(Models/Post-Training Inference.ipynb), this notebook shows how to:

1. Load the trained model
2. Evaluate it on new datasets
3. Predict individual image authenticity with confidence scores

### ğŸ§¹ Features

* Reusable image prediction function
* Custom image support
* Visualization with `matplotlib`
* Confidence scoring & binary classification

### ğŸ§  Key Findings

* Model loads reliably
* Generalizes well to unseen data
* Predicts and visualizes results accurately
* âœ… Accuracy on new dataset: **94%**

---

# ğŸŒ Flask Web App Deployment

A user-friendly **web app** that detects DeepFakes in videos by analyzing extracted frames with the trained CNN.

### âš™ï¸ Features

* ğŸ¥ Video upload interface
* ğŸ—„ï¸ Extracts 10 key frames
* ğŸ“‰ Efficient JPEG compression
* ğŸ§  CNN-based frame analysis
* ğŸ“Š Displays final result with confidence

---

## âœ¨ Getting Started

### ğŸ“¦ Prerequisites

* Python 3.8+
* pip

### ğŸ› ï¸ Installation

```bash
git clone https://github.com/yourusername/DeepFake-Photos-Genrator.git
cd DeepFake-Photos-Genrator
pip install -r requirements.txt
```

### â–¶ï¸ Run the App

```bash
python app.py
```

ğŸ”— App will run at: [http://localhost:5000](http://localhost:5000)

---

## ğŸ§¬ How It Works

1. **Upload** a short video
2. **Extract** 10 evenly spaced frames using OpenCV
3. **Compress** frames using Pillow
4. **Predict**:

   * Resize to 224x224
   * Normalize and input into the CNN
   * Average prediction scores
5. **Display** result + confidence percentage

---

## âš™ï¸ Tech Stack

* ğŸ **Flask** (Web Framework)
* ğŸ® **OpenCV** (Frame Extraction)
* ğŸ–¼ï¸ **PIL/Pillow** (Image Compression)
* ğŸ§  **TensorFlow** (Model)
* ğŸ§³ In-memory processing (No DB required)

---

## âš¡ Optimizations

* Only 10 frames analyzed â†’ faster
* Resized to 224x224 â†’ efficient model input
* Lossless JPEG compression â†’ memory saved
* One-time model load on startup
* No file storage â†’ privacy + speed

---

## ğŸ§‘â€ğŸ’» Customization

Replace the model path in `app.py`:

```python
# Load your trained model
model = tf.keras.models.load_model('path_to_your_model')
```

---

## ğŸ“Š Future Improvements

* ğŸ¥ The model was designed to analyze entire videos by extracting frames and predicting on each frame individually.
* âš ï¸ However, for advanced video-level analysis, the model requires a **real-world video dataset** to generalize more effectively.
* ğŸš€ Future versions could include:

  * Fine-tuning on real-life video footage
  * Integration with more advanced video forensics tools

---

## ğŸ“‚ Resources

* ğŸ”— [Training/Validation Dataset (Kaggle)](https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces)
* ğŸ”— [Evaluation Dataset (Kaggle)](https://www.kaggle.com/datasets/alaaeddineayadi/real-vs-ai-generated-faces)

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE)
