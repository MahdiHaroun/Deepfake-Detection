{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''import os\n",
        "import zipfile\n",
        "local_zip = 'real-vs-fake.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('')\n",
        "zip_ref.close()'''"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1746124847221
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikit-learn --upgrade\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as pl \n",
        "import os \n",
        "from tensorflow.keras.models import Sequential \n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping , ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers, models, regularizers"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: scikit-learn in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (1.6.1)\nRequirement already satisfied: numpy>=1.19.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from scikit-learn) (2.1.3)\nRequirement already satisfied: scipy>=1.6.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2025-05-01 18:41:19.497994: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746124880.472994    3603 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746124880.763810    3603 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1746124883.431029    3603 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1746124883.431052    3603 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1746124883.431055    3603 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1746124883.431057    3603 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n2025-05-01 18:41:23.711354: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1746124895813
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows, img_cols = 224 , 224\n",
        "batch_size = 32 \n",
        "SEED = 42 \n",
        "num_classes = 2 \n",
        "train_data_dir = 'real-vs-fake/train'\n",
        "validation_data_dir = 'real-vs-fake/valida'\n",
        "test_data_dir = 'real-vs-fake/test'\n",
        "labels = ['Real', 'Fake']\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1746124899514
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# For training data\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_data_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    seed=SEED,\n",
        "    shuffle=True\n",
        ").map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y)).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# For validation data\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    validation_data_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    seed=SEED,\n",
        "    shuffle=True\n",
        ").map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y)).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# For test data\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_data_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ").map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y)).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found 100000 files belonging to 2 classes.\nFound 20000 files belonging to 2 classes.\nFound 20000 files belonging to 2 classes.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "I0000 00:00:1746124913.401245    3603 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79088 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0001:00:00.0, compute capability: 8.0\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1746124920689
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "base_model = InceptionResNetV2(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(img_rows, img_cols, 3),\n",
        "    pooling='avg'\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m219055592/219055592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1746115672977
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers, models, regularizers\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "\n",
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "base_model = InceptionResNetV2(include_top=False, weights='imagenet', pooling='avg', input_tensor=input_tensor)\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = layers.Dense(512, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "x = layers.LeakyReLU(alpha=0.2)(x)  # use as a separate layer\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=input_tensor, outputs=output)\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1746117837973
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "\n",
        "\n",
        "def exp_decay(epoch):\n",
        "    initial_lrate = 1e-5\n",
        "    k = 0.1\n",
        "    return initial_lrate * np.exp(-k * epoch)\n",
        "\n",
        "class LossHistory_(Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current_lr = exp_decay(epoch)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(current_lr)\n",
        "        print(f\"Epoch {epoch+1} - Learning Rate: {current_lr:.6f}\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1746117841947
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1746117847836
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history_ = LossHistory_()\n",
        "lrate_ = LearningRateScheduler(exp_decay)\n",
        "\n",
        "keras_callbacks = [\n",
        "    EarlyStopping(monitor='loss', patience=5, mode='min', min_delta=0.01),\n",
        "    ModelCheckpoint(checkpoint_path, monitor='loss', save_best_only=True, mode='min')\n",
        "]\n",
        "\n",
        "callbacks_list = [loss_history_, lrate_] + keras_callbacks"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1746117857068
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, validation_data=val_ds, epochs=10, verbose=1, callbacks=callbacks_list)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/10\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6939 - loss: 5.8418Epoch 1 - Learning Rate: 0.000010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 38ms/step - accuracy: 0.6939 - loss: 5.8415 - val_accuracy: 0.7700 - val_loss: 4.7934 - learning_rate: 1.0000e-05\nEpoch 2/10\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7248 - loss: 4.6702Epoch 2 - Learning Rate: 0.000009\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 37ms/step - accuracy: 0.7248 - loss: 4.6701 - val_accuracy: 0.7872 - val_loss: 3.9821 - learning_rate: 9.0484e-06\nEpoch 3/10\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7400 - loss: 3.9238Epoch 3 - Learning Rate: 0.000008\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 34ms/step - accuracy: 0.7400 - loss: 3.9237 - val_accuracy: 0.7963 - val_loss: 3.4266 - learning_rate: 8.1873e-06\nEpoch 4/10\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7524 - loss: 3.4017Epoch 4 - Learning Rate: 0.000007\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 34ms/step - accuracy: 0.7524 - loss: 3.4017 - val_accuracy: 0.8052 - val_loss: 3.0353 - learning_rate: 7.4082e-06\nEpoch 5/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7614 - loss: 3.0349Epoch 5 - Learning Rate: 0.000007\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 34ms/step - accuracy: 0.7614 - loss: 3.0349 - val_accuracy: 0.8134 - val_loss: 2.7479 - learning_rate: 6.7032e-06\nEpoch 6/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7740 - loss: 2.7612Epoch 6 - Learning Rate: 0.000006\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 34ms/step - accuracy: 0.7741 - loss: 2.7612 - val_accuracy: 0.8162 - val_loss: 2.5320 - learning_rate: 6.0653e-06\nEpoch 7/10\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7812 - loss: 2.5525Epoch 7 - Learning Rate: 0.000005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 34ms/step - accuracy: 0.7812 - loss: 2.5524 - val_accuracy: 0.8231 - val_loss: 2.3624 - learning_rate: 5.4881e-06\nEpoch 8/10\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7852 - loss: 2.3888Epoch 8 - Learning Rate: 0.000005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 34ms/step - accuracy: 0.7852 - loss: 2.3888 - val_accuracy: 0.8251 - val_loss: 2.2292 - learning_rate: 4.9659e-06\nEpoch 9/10\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7909 - loss: 2.2619Epoch 9 - Learning Rate: 0.000004\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 34ms/step - accuracy: 0.7909 - loss: 2.2619 - val_accuracy: 0.8289 - val_loss: 2.1208 - learning_rate: 4.4933e-06\nEpoch 10/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7940 - loss: 2.1554Epoch 10 - Learning Rate: 0.000004\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 35ms/step - accuracy: 0.7940 - loss: 2.1554 - val_accuracy: 0.8312 - val_loss: 2.0303 - learning_rate: 4.0657e-06\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \nWARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "<keras.src.callbacks.history.History at 0x76fbd8283a00>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1746116992584
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[:450]:\n",
        "        layer.trainable = False"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1746117860632
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-6),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1746117865360
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, validation_data=val_ds, epochs=5, callbacks=callbacks_list)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/5\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6267 - loss: 7.7850Epoch 1 - Learning Rate: 0.000010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 37ms/step - accuracy: 0.6267 - loss: 7.7845 - val_accuracy: 0.7509 - val_loss: 5.9306 - learning_rate: 1.0000e-05\nEpoch 2/5\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6951 - loss: 5.7220Epoch 2 - Learning Rate: 0.000009\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 34ms/step - accuracy: 0.6951 - loss: 5.7219 - val_accuracy: 0.7764 - val_loss: 4.7061 - learning_rate: 9.0484e-06\nEpoch 3/5\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7186 - loss: 4.6285Epoch 3 - Learning Rate: 0.000008\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 35ms/step - accuracy: 0.7186 - loss: 4.6285 - val_accuracy: 0.7890 - val_loss: 3.9630 - learning_rate: 8.1873e-06\nEpoch 4/5\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7379 - loss: 3.9381Epoch 4 - Learning Rate: 0.000007\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 34ms/step - accuracy: 0.7379 - loss: 3.9380 - val_accuracy: 0.7977 - val_loss: 3.4600 - learning_rate: 7.4082e-06\nEpoch 5/5\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7449 - loss: 3.4741Epoch 5 - Learning Rate: 0.000007\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 34ms/step - accuracy: 0.7449 - loss: 3.4740 - val_accuracy: 0.8033 - val_loss: 3.0986 - learning_rate: 6.7032e-06\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "<keras.src.callbacks.history.History at 0x76fb93753460>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1746118427126
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"final_inceptionresnetv2_deepfake_model_74.h5\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1746118456886
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras import Model, Input, layers, regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "base_model = InceptionResNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "      \n",
        ")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1746124927562
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[:450]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    \n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1746124933250
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "\n",
        "model = models.Sequential([\n",
        "        base_model,                               \n",
        "        layers.GlobalAveragePooling2D(),         \n",
        "        layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)),  \n",
        "        layers.BatchNormalization(),            \n",
        "        layers.Dropout(0.5),                     \n",
        "        layers.Dense(1, activation='sigmoid')    \n",
        "    ])\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1746124934646
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Compile the model\n",
        "model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0001),  \n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1746124936217
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Stop if the validation loss is not improving\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history_fine_tune = model.fit(\n",
        "    train_ds,             \n",
        "    validation_data=val_ds,  \n",
        "    epochs=10,                  \n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 56ms/step - accuracy: 0.8618 - loss: 4.4749 - val_accuracy: 0.9718 - val_loss: 0.1884\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 54ms/step - accuracy: 0.9730 - loss: 0.1191 - val_accuracy: 0.9822 - val_loss: 0.0623\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 53ms/step - accuracy: 0.9865 - loss: 0.0461 - val_accuracy: 0.9753 - val_loss: 0.0786\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 53ms/step - accuracy: 0.9926 - loss: 0.0260 - val_accuracy: 0.9815 - val_loss: 0.0613\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 53ms/step - accuracy: 0.9930 - loss: 0.0269 - val_accuracy: 0.9814 - val_loss: 0.0586\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 52ms/step - accuracy: 0.9954 - loss: 0.0170 - val_accuracy: 0.9722 - val_loss: 0.0910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 53ms/step - accuracy: 0.9967 - loss: 0.0141 - val_accuracy: 0.9897 - val_loss: 0.0334\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 52ms/step - accuracy: 0.9972 - loss: 0.0112 - val_accuracy: 0.9918 - val_loss: 0.0271\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 52ms/step - accuracy: 0.9978 - loss: 0.0100 - val_accuracy: 0.9704 - val_loss: 0.1207\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/10\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 52ms/step - accuracy: 0.9973 - loss: 0.0105 - val_accuracy: 0.9037 - val_loss: 0.4831\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1746126662344
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"final_inceptionresnetv2_deepfake_model_99_new.h5\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1746126760575
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_ds, verbose=1)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.9918 - loss: 0.0254\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTest Loss: 0.0292\nTest Accuracy: 0.9909\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1746126695671
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.10 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}